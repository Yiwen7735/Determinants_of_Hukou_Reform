{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        #  sample\n",
      "Year             \n",
      "2010  945    94.5\n",
      "2011  867    86.7\n",
      "2012  541    54.1\n",
      "2013  403    40.3\n",
      "2014  341    34.1\n",
      "2015  403    40.3\n",
      "2016  334    33.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Year    2012.216710\n",
       "#         32.078329\n",
       "pos        0.665796\n",
       "dis        0.214099\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from functools import reduce\n",
    "import random\n",
    "df = pd.read_csv('savedf.csv')\n",
    "\n",
    "# 1. Preparation for Labeling\n",
    "\n",
    "# 1.1 Check the sample size\n",
    "n = df.groupby('Year').agg({\"#\":\"count\"})\n",
    "n['sample'] = n['#']*0.1\n",
    "print(n)\n",
    "\n",
    "# 1.2 Generate random integers without replacement to select rows from each year\n",
    "random.seed(7735)\n",
    "\n",
    "def sample(l, size):\n",
    "    sample = random.sample(range(1, l+1), size) \n",
    "    return sample\n",
    "\n",
    "s10 = sample(945, 95)\n",
    "s11 = sample(867, 87)\n",
    "s12 = sample(541, 54)\n",
    "s13 = sample(403, 40)\n",
    "s14 = sample(341, 34)\n",
    "s15 = sample(403, 40)\n",
    "s16 = sample(334, 33)\n",
    "\n",
    "# 1.3 Select all the training data for labeling\n",
    "df10 = df[df['Year'] == 2010]\n",
    "df11 = df[df['Year'] == 2011]\n",
    "df12 = df[df['Year'] == 2012]\n",
    "df13 = df[df['Year'] == 2013]\n",
    "df14 = df[df['Year'] == 2014]\n",
    "df15 = df[df['Year'] == 2015]\n",
    "df16 = df[df['Year'] == 2016]\n",
    "\n",
    "train10 = df10[df10['#'].isin(s10)]\n",
    "train11 = df11[df11['#'].isin(s11)]\n",
    "train12 = df12[df12['#'].isin(s12)]\n",
    "train13 = df13[df13['#'].isin(s13)]\n",
    "train14 = df14[df14['#'].isin(s14)]\n",
    "train15 = df15[df15['#'].isin(s15)]\n",
    "train16 = df16[df16['#'].isin(s16)]\n",
    "\n",
    "# 1.4 Mannually label train10~train16 in the file label.xlsx\n",
    "lab = pd.read_excel('label.xlsx')\n",
    "np.mean(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split the Labeled and Unlabeled Data\n",
    "\n",
    "def combine(train, Year):\n",
    "    train.loc[:,['pos', 'dis']] = np.array(lab.loc[lab['Year'] == Year, ['pos', 'dis']])\n",
    "    return train\n",
    "\n",
    "labeled = reduce(lambda top, bottom: top.append(bottom), \n",
    "               [combine(train10, 2010), combine(train11, 2011), combine(train12, 2012), combine(train13, 2013),\n",
    "                combine(train14, 2014), combine(train15, 2015), combine(train16, 2016)])\n",
    "\n",
    "unlabeled_index = list(set(df.index) - set(labeled.index))\n",
    "unlabeled = df.iloc[unlabeled_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83515957 0.86370931 0.86835905 0.87530832]\n",
      "[0.90080009 0.95506418 0.97763172 0.99998937]\n",
      "0.65 0.65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.890110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "recall     0.923077\n",
       "precision  0.923077\n",
       "f1         0.923077\n",
       "roc_auc    0.890110\n",
       "accuracy   0.900000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Model Selection on the Labeled Data —— Positive Coverage ('pos')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "# 3.1 Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(labeled['Text_truncated'], list(labeled['pos']), random_state=0, test_size=0.05)\n",
    "\n",
    "vec = CountVectorizer().fit(X_train)\n",
    "X_train_vec = vec.transform(X_train)\n",
    "#lname = vec.get_feature_names()\n",
    "#max(lname, key=len)\n",
    "\n",
    "# 3.2 Search for the best parameter(s)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb_param = {'alpha': [10, 50, 100, 500, 750, 1000]}\n",
    "\n",
    "lg = LogisticRegression(solver='liblinear', max_iter=500)\n",
    "lg_param = {'C':[0.0001, 0.0005, 0.001, 0.01]}\n",
    "             \n",
    "clf_pos = GridSearchCV(lg, param_grid=lg_param, scoring='roc_auc', cv=5, iid=True, return_train_score=True).fit(X_train_vec, y_train)\n",
    "\n",
    "print(clf_pos.cv_results_['mean_test_score'])\n",
    "print(clf_pos.cv_results_['mean_train_score'])\n",
    "\n",
    "# 3.3 Check the performance on the test data\n",
    "\n",
    "pos = clf_pos.predict(vec.transform(X_test))\n",
    "print(np.mean(pos), np.mean(y_test)) \n",
    "\n",
    "def scores(y_pre): \n",
    "    rec = recall_score(y_pre, y_test)\n",
    "    pre = precision_score(y_pre, y_test)\n",
    "    f1 = f1_score(y_pre, y_test)\n",
    "    auc = roc_auc_score(y_pre, y_test)\n",
    "    acc = accuracy_score(y_pre, y_test)\n",
    "\n",
    "    return pd.DataFrame({'scores':[rec,pre,f1,auc,acc]}, index=['recall','precision','f1','roc_auc','accuracy'])\n",
    "\n",
    "scores(pos)\n",
    "\n",
    "# Conclusion: Logistic regression is better at predicting positive coverage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89909862 0.88626387 0.88387576 0.83998384 0.82088404 0.78561497]\n",
      "[0.99779613 0.99778468 0.99747485 0.94161013 0.89526415 0.85091727]\n",
      "0.21875 0.22916666666666666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.932381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.947917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "recall     0.904762\n",
       "precision  0.863636\n",
       "f1         0.883721\n",
       "roc_auc    0.932381\n",
       "accuracy   0.947917"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Model Selection on the Labeled Data —— Labor Disputes ('dis')\n",
    "\n",
    "# 4.1 Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(labeled['Text_truncated'], list(labeled['dis']), random_state=0, test_size=0.25)\n",
    "vec = CountVectorizer().fit(X_train)\n",
    "X_train_vec = vec.transform(X_train)\n",
    "\n",
    "\n",
    "# 4.2 Parameter search\n",
    "mnb_param_d = {'alpha': [0.1, 0.5, 1, 5, 10, 25]}\n",
    "lg_param_d = {'C':[0.0001, 0.0005, 0.001, 0.01]}\n",
    "\n",
    "clf_dis = GridSearchCV(mnb, param_grid=mnb_param_d, scoring='roc_auc', cv=5, iid=True, return_train_score=True).fit(X_train_vec, y_train)\n",
    "print(clf_dis.cv_results_['mean_test_score'])\n",
    "print(clf_dis.cv_results_['mean_train_score'])\n",
    "\n",
    "# 4.3 Check performance on test data\n",
    "\n",
    "dis = clf_dis.predict(vec.transform(X_test))\n",
    "print(np.mean(dis), np.mean(y_test))\n",
    "\n",
    "scores(dis)\n",
    "\n",
    "# Conclusion: Multinomial naive bayes is better at predicting disputes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83515957 0.86370931 0.86835905 0.87530832]\n",
      "[0.90080009 0.95506418 0.97763172 0.99998937]\n",
      "[0.89909862 0.88626387 0.88387576 0.83998384 0.82088404 0.78561497]\n",
      "[0.99779613 0.99778468 0.99747485 0.94161013 0.89526415 0.85091727]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7299333526514054, 0.209214720370907)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 Make Predictions Using all Labelled Data\n",
    "text = labeled['Text_truncated']\n",
    "ypos = list(labeled['pos'])\n",
    "ydis = list(labeled['dis'])\n",
    "\n",
    "vec = CountVectorizer().fit(text)\n",
    "predictor = vec.transform(text)\n",
    "\n",
    "cls_pos = GridSearchCV(lg, param_grid=lg_param, cv=5, iid=True, return_train_score=True).fit(predictor, ypos)\n",
    "print(clf_pos.cv_results_['mean_test_score'])\n",
    "print(clf_pos.cv_results_['mean_train_score'])\n",
    "\n",
    "cls_dis = GridSearchCV(mnb, param_grid=mnb_param_d, cv=5, iid=True, return_train_score=True).fit(predictor, ydis)\n",
    "print(clf_dis.cv_results_['mean_test_score'])\n",
    "print(clf_dis.cv_results_['mean_train_score'])\n",
    "\n",
    "pred_pos = cls_pos.predict(vec.transform(unlabeled['Text_truncated']))\n",
    "pred_dis = cls_dis.predict(vec.transform(unlabeled['Text_truncated']))\n",
    "\n",
    "np.mean(pred_pos), np.mean(pred_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>dis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Province</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"29\" valign=\"top\">2010</th>\n",
       "      <th>Anhui</th>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.140351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beijing</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chongqing</th>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fujian</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gansu</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guangdong</th>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guangxi</th>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guizhou</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hainan</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hebei</th>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heilongjiang</th>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.180328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Henan</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hubei</th>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hunan</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inner Mongolia</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jiangsu</th>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jiangxi</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jilin</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liaoning</th>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qinghai</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shaanxi</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shandong</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shanghai</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shanxi</th>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sichuan</th>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.146341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tianjin</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xinjiang</th>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yunnan</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zhejiang</th>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.139535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <th>Anhui</th>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.283019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <th>Zhejiang</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"29\" valign=\"top\">2016</th>\n",
       "      <th>Anhui</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beijing</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chongqing</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fujian</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gansu</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guangdong</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guangxi</th>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guizhou</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hainan</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hebei</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heilongjiang</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Henan</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hubei</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hunan</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inner Mongolia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jiangsu</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jiangxi</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jilin</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liaoning</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qinghai</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shaanxi</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shandong</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shanghai</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shanxi</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sichuan</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tianjin</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xinjiang</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yunnan</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zhejiang</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pos       dis\n",
       "Year Province                          \n",
       "2010 Anhui           0.771930  0.140351\n",
       "     Beijing         0.800000  0.333333\n",
       "     Chongqing       0.676471  0.058824\n",
       "     Fujian          0.823529  0.235294\n",
       "     Gansu           0.807692  0.115385\n",
       "     Guangdong       0.693548  0.016129\n",
       "     Guangxi         0.681818  0.136364\n",
       "     Guizhou         0.809524  0.095238\n",
       "     Hainan          0.800000  0.400000\n",
       "     Hebei           0.821429  0.357143\n",
       "     Heilongjiang    0.606557  0.180328\n",
       "     Henan           0.666667  0.277778\n",
       "     Hubei           0.711111  0.266667\n",
       "     Hunan           0.760000  0.080000\n",
       "     Inner Mongolia  0.941176  0.647059\n",
       "     Jiangsu         0.760870  0.152174\n",
       "     Jiangxi         0.833333  0.291667\n",
       "     Jilin           0.791667  0.125000\n",
       "     Liaoning        0.884615  0.153846\n",
       "     Qinghai         0.888889  0.444444\n",
       "     Shaanxi         0.769231  0.307692\n",
       "     Shandong        0.800000  0.200000\n",
       "     Shanghai        0.720000  0.000000\n",
       "     Shanxi          0.774194  0.193548\n",
       "     Sichuan         0.804878  0.146341\n",
       "     Tianjin         0.615385  0.153846\n",
       "     Xinjiang        0.827586  0.379310\n",
       "     Yunnan          0.529412  0.000000\n",
       "     Zhejiang        0.906977  0.139535\n",
       "2011 Anhui           0.773585  0.283019\n",
       "...                       ...       ...\n",
       "2015 Zhejiang        0.555556  0.111111\n",
       "2016 Anhui           0.857143  0.428571\n",
       "     Beijing         0.500000  0.250000\n",
       "     Chongqing       0.500000  0.125000\n",
       "     Fujian          0.900000  0.400000\n",
       "     Gansu           0.500000  0.125000\n",
       "     Guangdong       0.750000  0.083333\n",
       "     Guangxi         0.840000  0.200000\n",
       "     Guizhou         0.777778  0.000000\n",
       "     Hainan          0.714286  0.571429\n",
       "     Hebei           0.923077  0.692308\n",
       "     Heilongjiang    0.666667  0.222222\n",
       "     Henan           0.666667  0.166667\n",
       "     Hubei           0.800000  0.200000\n",
       "     Hunan           0.714286  0.142857\n",
       "     Inner Mongolia  0.000000  0.000000\n",
       "     Jiangsu         0.714286  0.071429\n",
       "     Jiangxi         0.750000  0.375000\n",
       "     Jilin           0.750000  0.250000\n",
       "     Liaoning        0.900000  0.200000\n",
       "     Qinghai         0.750000  0.416667\n",
       "     Shaanxi         0.782609  0.391304\n",
       "     Shandong        0.500000  0.500000\n",
       "     Shanghai        1.000000  0.200000\n",
       "     Shanxi          0.857143  0.428571\n",
       "     Sichuan         0.789474  0.473684\n",
       "     Tianjin         0.400000  0.000000\n",
       "     Xinjiang        1.000000  0.500000\n",
       "     Yunnan          0.588235  0.294118\n",
       "     Zhejiang        0.666667  0.000000\n",
       "\n",
       "[203 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Prepare Data for Regression Analysis\n",
    "\n",
    "unlabeled.loc[:, \"pos\"]= pred_pos\n",
    "unlabeled.loc[:, 'dis'] = pred_dis\n",
    "cols = labeled.append(unlabeled).groupby([\"Year\", \"Province\"])[[\"pos\", \"dis\"]].mean()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.to_excel(\"pos_dis_allyear.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
