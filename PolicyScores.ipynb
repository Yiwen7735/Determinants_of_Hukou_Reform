{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aim of this code is to generate \n",
    "# 1. a set of outcomes used in the analysis of hukou reform determinants\n",
    "# 2. a set of covariates used in the analysis of hukou reform impacts - provincial level\n",
    "# 3. a set of covariates used in the analysis of hukou reform impacts - city level\n",
    "\n",
    "# The data set used in this code is generated by the author based on original policy documents issued by each Chinese province\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 0. Read the data and assign weight to each row\n",
    "\n",
    "policy = pd.read_excel(\"PolicyData.xlsx\", index_col=0)\n",
    "policy['score'] = policy['res_all'] * policy['mag_all']\n",
    "policy = policy[policy['score'] < 5]\n",
    "\n",
    "mig_weight = {10:1, 20:0.73, 21:0.63, 22:0.63, 23:0.11, 30:0.56, 31:0.45, 32:0.11, 33:0.11, 40:0.01, 41:0.01, 42:0.01, \n",
    "              50:1.00, 51:0.73, 52:0.17, 53:0.1, 54:0.17, 61:0.11, 62:0.63, 63:0.01, 64:0.01, 65:0.01}\n",
    "\n",
    "policy['weight'] = [mig_weight[i] for i in policy['mig_group']]\n",
    "policy['wscore'] = policy['score'] * policy['weight']\n",
    "\n",
    "\n",
    "def subset(data, col, v1, v2 = None, v3 = None, v4 = None, v5 = None, v6 = None, v7 = None):\n",
    "    return data.loc[(data[col] == v1) | (data[col] == v2) | (data[col] == v3) | (data[col] == v4) | \n",
    "                    (data[col] == v5) | (data[col] == v6) | (data[col] == v7), :]\n",
    "\n",
    "def ts(subset = policy, score_type = \"score\", code_value = 1, by_col = \"pol_area\"):\n",
    "    return subset.loc[subset[by_col] == code_value, score_type].groupby(level=0).sum()\n",
    "\n",
    "\n",
    "def avg(subset = policy, score_type = \"score\", code_value = 1, by_col = \"pol_area\"):\n",
    "    return subset.loc[subset[by_col] == code_value, score_type].groupby(level=0).mean()\n",
    "\n",
    "\n",
    "def count(subset = policy, code_value = 1, by_col = \"pol_area\", score_type = \"res_all\"):\n",
    "    return subset.loc[subset[by_col] == code_value, score_type].groupby(level=0).count()\n",
    "\n",
    "\n",
    "# 1. Outcomes used for determinants analysis\n",
    "\n",
    "# The set of outcomes refers to the policy scores disaggregated by policy areas (selection & integration), including\n",
    "\n",
    "# A. total and average selection scores (weighted and unweighted)\n",
    "# B. total and average selection scores targeting low/high-skilled migrants (weighted and unweighted)\n",
    "# C. total and average selection scores by different city sizes (weighted and unweighted)\n",
    "# D. total and average integration scores (unweighted)\n",
    "# E. Number of more lenient selection and integration measures\n",
    "\n",
    "# 1.1 Construct A, D & E\n",
    "\n",
    "ts_sel = ts()\n",
    "as_sel = avg()\n",
    "\n",
    "wts_sel = ts(policy, \"wscore\")\n",
    "was_sel = avg(policy, \"wscore\")\n",
    "\n",
    "ts_int = ts(policy, \"score\", 2)\n",
    "as_int = avg(policy, \"score\", 2)\n",
    "\n",
    "num_ls = count(subset(policy, \"res_all\", -1))\n",
    "num_li = count(subset(policy, \"res_all\", -1), 2)\n",
    "\n",
    "                \n",
    "# 1.2 Construct B\n",
    "\n",
    "lts_sel = ts(subset(policy, \"mig_group\", 20, 21, 22, 30, 31))\n",
    "las_sel = avg(subset(policy, \"mig_group\", 20, 21, 22, 30, 31))\n",
    "               \n",
    "wlts_sel = ts(subset(policy, \"mig_group\", 20, 21, 22, 30, 31), \"wscore\")\n",
    "wlas_sel = avg(subset(policy, \"mig_group\", 20, 21, 22, 30, 31), \"wscore\")\n",
    "\n",
    "hts_sel = ts(subset(policy, \"mig_group\", 23, 32, 33))\n",
    "has_sel = avg(subset(policy, \"mig_group\", 23, 32, 33))\n",
    "               \n",
    "whts_sel = ts(subset(policy, \"mig_group\", 23, 32, 33), \"wscore\")\n",
    "whas_sel = avg(subset(policy, \"mig_group\", 23, 32, 33), \"wscore\")               \n",
    "            \n",
    "               \n",
    "# 1.3 Construct C\n",
    "\n",
    "ts_small = ts(subset(policy, \"des\", 11))\n",
    "as_small = avg(subset(policy, \"des\", 11))\n",
    "\n",
    "wts_small = ts(subset(policy, \"des\", 11), \"wscore\")\n",
    "was_small = avg(subset(policy, \"des\", 11), \"wscore\")\n",
    "\n",
    "\n",
    "ts_medium = ts(subset(policy, \"des\", 12))\n",
    "as_medium = avg(subset(policy, \"des\", 12))\n",
    "\n",
    "wts_medium = ts(subset(policy, \"des\", 12), \"wscore\")\n",
    "was_medium = avg(subset(policy, \"des\", 12), \"wscore\")\n",
    "\n",
    "\n",
    "ts_big = ts(subset(policy, \"des\", 13, 14, 15))\n",
    "as_big = avg(subset(policy, \"des\", 13, 14, 15))\n",
    "\n",
    "wts_big = ts(subset(policy, \"des\", 13, 14, 15), \"wscore\")\n",
    "was_big = avg(subset(policy, \"des\", 13, 14, 15), \"wscore\")\n",
    "\n",
    "\n",
    "ts_mega = ts(subset(policy, \"des\", 16))\n",
    "as_mega = avg(subset(policy, \"des\", 16))\n",
    "\n",
    "wts_mega = ts(subset(policy, \"des\", 16), \"wscore\")\n",
    "was_mega = avg(subset(policy, \"des\", 16), \"wscore\")\n",
    "\n",
    "\n",
    "ts_big_mega = ts(subset(policy, \"des\", 13, 14, 15, 16))\n",
    "as_big_mega = avg(subset(policy, \"des\", 13, 14, 15, 16))\n",
    "\n",
    "wts_big_mega = ts(subset(policy, \"des\", 13, 14, 15, 16), \"wscore\")\n",
    "was_big_mega = avg(subset(policy, \"des\", 13, 14, 15, 16), \"wscore\")\n",
    "\n",
    "\n",
    "df1 = pd.concat([ts_sel, as_sel, wts_sel, was_sel, lts_sel, las_sel, wlts_sel, wlas_sel,\n",
    "                ts_small, ts_medium, ts_big, ts_mega, ts_big_mega, as_small, as_medium, as_big, as_mega, as_big_mega, \n",
    "                wts_small, wts_medium, wts_big, wts_mega, wts_big_mega, was_small, was_medium, was_big, was_mega, was_big_mega,\n",
    "                ts_int, as_int, num_ls, num_li], axis=1).fillna(0)\n",
    "\n",
    "df1.columns = [\"ts_sel\", \"as_sel\", \"wts_sel\", \"was_sel\", \"lts_sel\", \"las_sel\", \"wlts_sel\", \"wlas_sel\",\n",
    "              \"ts_small\", \"ts_medium\", \"ts_big\", \"ts_mega\", \"ts_big_mega\", \n",
    "              \"as_small\", \"as_medium\", \"as_big\", \"as_mega\", \"as_big_mega\",\n",
    "              \"wts_small\", \"wts_medium\", \"wts_big\", \"wts_mega\", \"wts_big_mega\",\n",
    "              \"was_small\", \"was_medium\", \"was_big\", \"was_mega\", \"was_big_mega\",\n",
    "              \"ts_int\", \"as_int\", \"num_ls\", \"num_li\"]\n",
    "\n",
    "df1.to_excel(r\"C:\\Users\\User\\Desktop\\Clustering\\Scores_Province_Area.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. Covariates used for Impact analysis - provincial level\n",
    "\n",
    "# The set of covariates refers to the (unweighted) total and average policy scores disaggregated by the following tools:\n",
    "\n",
    "# A. access to local hukou (access)\n",
    "# B. points system (ps)\n",
    "# C. residential permit (rp)\n",
    "# D. urban-rural unification (unify)\n",
    "# E. public service-related tools (ser)\n",
    "# F. insurance-related  tools (insr)\n",
    "\n",
    "\n",
    "ts_lower = ts(policy, \"score\", 11, \"pol_tool\")\n",
    "as_lower = avg(policy, \"score\", 11, \"pol_tool\")\n",
    "\n",
    "ts_ps = ts(policy, \"score\", 12, \"pol_tool\")\n",
    "as_ps = avg(policy, \"score\", 12, \"pol_tool\")\n",
    "\n",
    "ts_rp = ts(policy, \"score\", 21, \"pol_tool\")\n",
    "as_rp = avg(policy, \"score\", 21, \"pol_tool\")\n",
    "\n",
    "ts_unify = ts(policy, \"score\", 23, \"pol_tool\")\n",
    "as_unify = avg(policy, \"score\", 23, \"pol_tool\")\n",
    " \n",
    "ts_ser = ts(subset(policy, \"pol_tool\", 30, 31, 36, 37, 38, 39, 54), \"score\", 2)\n",
    "as_ser = avg(subset(policy, \"pol_tool\", 30, 31, 36, 37, 38, 39, 54), \"score\", 2)\n",
    "\n",
    "ts_insr = ts(subset(policy, \"pol_tool\", 32, 33, 34, 35), \"score\", 2)\n",
    "as_insr = avg(subset(policy, \"pol_tool\", 32, 33, 34, 35), \"score\", 2)\n",
    "\n",
    "ts_edu = ts(policy, \"score\", 31, \"pol_tool\")\n",
    "as_edu = avg(policy, \"score\", 31, \"pol_tool\")\n",
    "\n",
    "df2 = pd.concat([ts_lower, as_lower, ts_ps, as_ps, \n",
    "                 ts_rp, as_rp, ts_unify, as_unify, ts_ser, as_ser, ts_insr, as_insr, ts_edu, as_edu], axis=1).fillna(0)\n",
    "\n",
    "df2.columns = [\"ts_lower\", \"as_lower\", \"ts_ps\", \"as_ps\",\n",
    "               \"ts_rp\", \"as_rp\", \"ts_unify\", \"as_unify\", \"ts_ser\", \"as_ser\", \"ts_insr\", \"as_insr\", \"ts_edu\", \"as_edu\"]\n",
    "\n",
    "df2.to_excel(r\"C:\\Users\\User\\Desktop\\Clustering\\Scores_Province_Tools.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# 3. Covariates used for Impact analysis - city level\n",
    "\n",
    "# The set of covariates consists primarily of the previously constructed variables disaggregated by the following city sizes:\n",
    "\n",
    "# A. small city (population < 500,000)\n",
    "# B. medium (500,000 ~ 1 million)\n",
    "# C. big I (1 ~ 3 million)\n",
    "# D. big II (3 ~ 5 milion)\n",
    "# E. mega ( > 5 million)\n",
    "\n",
    "des = {11:\"small\", 12:\"medium\", 13:\"big I\", 14:\"big II\", 15:\"big\", 16:\"mega\", \n",
    "       17:\"small & medium\", 18:\"medium & big\", 19:\"big & mega\", 99:\"all sizes\"}\n",
    "\n",
    "small = subset(policy, \"des\", 11, 17, 99)\n",
    "medium = subset(policy, \"des\", 12, 17, 18, 99)\n",
    "big1 = subset(policy, \"des\", 13, 15, 18, 19, 99)\n",
    "big2 = subset(policy, \"des\", 14, 15, 18, 19, 99)\n",
    "mega = subset(policy, \"des\", 16, 19, 99)\n",
    "\n",
    "\n",
    "def gen_df(df, pre):\n",
    "    return pd.DataFrame({pre + \"ts_sel\": ts(df),\n",
    "                         pre + \"as_sel\": avg(df),\n",
    "                         pre + \"ts_access\": ts(df, \"score\", 11, \"pol_tool\"),\n",
    "                         pre + \"as_access\": avg(df, \"score\", 11, \"pol_tool\"),\n",
    "                         pre + \"ts_ps\": ts(df, \"score\", 12, \"pol_tool\"),\n",
    "                         pre + \"as_ps\": avg(df, \"score\", 12, \"pol_tool\"),\n",
    "                         pre + \"wts_sel\": ts(df, \"wscore\"), \n",
    "                         pre + \"was_sel\": avg(df, \"wscore\"),\n",
    "                         pre + \"lts_sel\": ts(subset(df, \"mig_group\", 20, 21, 22, 30, 31)),\n",
    "                         pre + \"las_sel\": avg(subset(df, \"mig_group\", 20, 21, 22, 30, 31)),\n",
    "                         pre + \"hts_sel\": ts(subset(df, \"mig_group\", 23, 32, 33)),\n",
    "                         pre + \"has_sel\": avg(subset(df, \"mig_group\", 23, 32, 33)),\n",
    "                         pre + \"num_ls\": count(subset(policy, \"res_all\", -1)),\n",
    "                         pre + \"num_li\": count(subset(policy, \"res_all\", -1), 2),\n",
    "                         pre + \"ts_int\": ts(df, \"score\", 2),\n",
    "                         pre + \"as_int\": avg(df, \"score\", 2),\n",
    "                         pre + \"ts_rp\": ts(df, \"score\", 21, \"pol_tool\"),\n",
    "                         pre + \"as_rp\": avg(df, \"score\", 21, \"pol_tool\"),\n",
    "                         pre + \"ts_unify\": ts(df, \"score\", 23, \"pol_tool\"),\n",
    "                         pre + \"as_unify\": avg(df, \"score\", 23, \"pol_tool\"),\n",
    "                         pre + \"ts_ser\": ts(subset(df, \"pol_tool\", 30, 31, 36, 37, 38, 39, 54), \"score\", 2),\n",
    "                         pre + \"as_ser\": avg(subset(df, \"pol_tool\", 30, 31, 36, 37, 38, 39, 54), \"score\", 2),\n",
    "                         pre + \"ts_insr\": ts(subset(df, \"pol_tool\", 32, 33, 34, 35), \"score\", 2),\n",
    "                         pre + \"as_insr\": avg(subset(df, \"pol_tool\", 32, 33, 34, 35), \"score\", 2)}).fillna(0)\n",
    "\n",
    "\n",
    "df3 = pd.concat([gen_df(small, \"small_\"), gen_df(medium, \"medium_\"),\n",
    "                 gen_df(big1, \"big1_\"),  gen_df(big2, \"big2_\"), gen_df(mega, \"mega_\")], axis = 1)\n",
    "\n",
    "df3.to_excel(r\"C:\\Users\\User\\Desktop\\Clustering\\Scores_City.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
