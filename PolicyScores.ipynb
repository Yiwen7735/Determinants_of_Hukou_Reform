{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aim of this code is to generate a set of outcomes used in the analysis of hukou reform determinants\n",
    "# The set of outcomes is composed of \n",
    "# 1) policy scores disaggregated by policy areas, tools, targeted migrant categories, targeted city sizes\n",
    "# 2) clustets assigned to each province according to various score combinations\n",
    "\n",
    "# The data set used in this code is generated by the author based on original policy documents issued by each Chinese province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the data and assign weight to each row\n",
    "\n",
    "policy = pd.read_excel(\"PolicyData.xlsx\", index_col=0)\n",
    "policy['score'] = policy['res_all'] * policy['mag_all']\n",
    "policy = policy[policy['score'] < 5]\n",
    "\n",
    "mig_weight = {10:1, 20:0.73, 21:0.63, 22:0.63, 23:0.11, 30:0.56, 31:0.45, 32:0.11, 33:0.11, 40:0.01, 41:0.01, 42:0.01, \n",
    "              50:1.00, 51:0.73, 52:0.17, 53:0.1, 54:0.17, 61:0.11, 62:0.63, 63:0.01, 64:0.01, 65:0.01}\n",
    "\n",
    "policy['weight'] = [mig_weight[i] for i in policy['mig_group']]\n",
    "policy['wscore'] = policy['score'] * policy['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Disaggregate policy scores by policy areas\n",
    "    \n",
    "def subset(data, col, v1, v2 = None, v3 = None, v4 = None, v5 = None):\n",
    "    if v2 == None: \n",
    "        v2 = v1\n",
    "    if v3 == None:\n",
    "        v3 = v2\n",
    "    return data.loc[(data[col] == v1) | (data[col] == v2) | (data[col] == v3) | (data[col] == v4) | (data[col] == v5), :]\n",
    "\n",
    "\n",
    "def ts(subset, col, name):\n",
    "    return pd.DataFrame(subset[col].groupby(level=0).sum()).rename(columns={col:name})\n",
    "\n",
    "\n",
    "def avg(subset, col, name):\n",
    "    return pd.DataFrame(subset[col].groupby(level=0).mean()).rename(columns={col:name})\n",
    "\n",
    "\n",
    "def count(subset, col, name):\n",
    "    return pd.DataFrame(subset[col].groupby(level=0).count()).rename(columns={col:name})\n",
    "\n",
    "# 2.1 Policies targeting selection and integration area (scores and number of measures)\n",
    "\n",
    "policy_sel = subset(policy, \"pol_area\", 1)\n",
    "policy_int = subset(policy, \"pol_area\", 2)\n",
    "\n",
    "ts_all = ts(policy, \"score\", \"ts_all\")\n",
    "as_all = avg(policy, \"score\", \"as_all\")\n",
    "\n",
    "ts_sel = ts(policy_sel, \"score\", \"ts_sel\")\n",
    "as_sel = avg(policy_sel, \"score\", \"as_sel\")\n",
    "\n",
    "wts_sel = ts(policy_sel, \"wscore\", \"wts_sel\")\n",
    "was_sel = avg(policy_sel, \"wscore\", \"was_sel\")\n",
    "\n",
    "ts_int = ts(policy_int, \"score\", \"ts_int\")\n",
    "as_int = avg(policy_int, \"score\", \"as_int\")\n",
    "\n",
    "num_ls = count(subset(policy_sel, \"res_all\", -1), \"res_all\", \"num_ls\")\n",
    "num_li = count(subset(policy_int, \"res_all\", -1), \"res_all\", \"num_li\")\n",
    "\n",
    "# 2.2 Policies targeting low-skilled migrants & high-skilled migrants specifically\n",
    "\n",
    "policy_lsel = subset(policy_sel, \"mig_group\", 20, 21, 22, 30, 31)\n",
    "\n",
    "lts_sel = ts(policy_lsel, \"score\", \"lts_sel\")\n",
    "las_sel = avg(policy_lsel, \"score\", \"las_sel\")\n",
    "wlts_sel = ts(policy_lsel, \"wscore\", \"wlts_sel\")\n",
    "wlas_sel = avg(policy_lsel, \"wscore\", \"wlas_sel\")\n",
    "\n",
    "policy_hsel = subset(policy_sel, \"mig_group\", 23, 32, 33)\n",
    "\n",
    "hts_sel = ts(policy_hsel, \"score\", \"hts_sel\")\n",
    "has_sel = avg(policy_hsel, \"score\", \"has_sel\")\n",
    "whts_sel = ts(policy_hsel, \"wscore\", \"whts_sel\")\n",
    "whas_sel = avg(policy_hsel, \"wscore\", \"whas_sel\")\n",
    "\n",
    "# 2.3 Policies targeting cities of different size\n",
    "\n",
    "policy_small = subset(policy_sel, \"des\", 11)\n",
    "\n",
    "ts_small = ts(policy_small, \"score\", \"ts_small\")\n",
    "as_small = avg(policy_small, \"score\", \"as_small\")\n",
    "\n",
    "wts_small = ts(policy_small, \"wscore\", \"wts_small\")\n",
    "was_small = avg(policy_small, \"wscore\", \"was_small\")\n",
    "\n",
    "\n",
    "policy_medium = subset(policy_sel, \"des\", 12)\n",
    "\n",
    "ts_medium = ts(policy_small, \"score\", \"ts_medium\")\n",
    "as_medium = avg(policy_small, \"score\", \"as_medium\")\n",
    "\n",
    "wts_medium = ts(policy_small, \"wscore\", \"wts_medium\")\n",
    "was_medium = avg(policy_small, \"wscore\", \"was_medium\")\n",
    "\n",
    "\n",
    "policy_big = subset(policy_sel, \"des\", 13, 14, 15)\n",
    "\n",
    "ts_big = ts(policy_big, \"score\", \"ts_big\")\n",
    "as_big = avg(policy_big, \"score\", \"as_big\")\n",
    "\n",
    "wts_big = ts(policy_big, \"wscore\", \"wts_big\")\n",
    "was_big = avg(policy_big, \"wscore\", \"was_big\")\n",
    "\n",
    "\n",
    "policy_mega = subset(policy_sel, \"des\", 16)\n",
    "\n",
    "ts_mega = ts(policy_mega, \"score\", \"ts_mega\")\n",
    "as_mega = avg(policy_mega, \"score\", \"as_mega\")\n",
    "\n",
    "wts_mega = ts(policy_mega, \"wscore\", \"wts_mega\")\n",
    "was_mega = avg(policy_mega, \"wscore\", \"was_mega\")\n",
    "\n",
    "\n",
    "policy_big_mega = subset(policy_sel, \"des\", 13, 14, 15, 16)\n",
    "\n",
    "ts_big_mega = ts(policy_big_mega, \"score\", \"ts_big_mega\")\n",
    "as_big_mega = avg(policy_big_mega, \"score\", \"as_big_mega\")\n",
    "\n",
    "wts_big_mega = ts(policy_big_mega, \"wscore\", \"wts_big_mega\")\n",
    "was_big_mega = avg(policy_big_mega, \"wscore\", \"was_big_mega\")\n",
    "\n",
    "# 2.4 Policies using specific policy tools (strict definition - e.g., collective hukou cannot be considered as rp)\n",
    "\n",
    "ts_lower = ts(subset(policy, \"pol_tool\", 11), \"score\", \"ts_lower\")\n",
    "as_lower = avg(subset(policy, \"pol_tool\", 11), \"score\", \"as_lower\")\n",
    "\n",
    "ts_ps = ts(subset(policy, \"pol_tool\", 12), \"score\", \"ts_ps\")\n",
    "as_ps = avg(subset(policy, \"pol_tool\", 12), \"score\", \"as_ps\")\n",
    "\n",
    "ts_rp = ts(subset(policy, \"pol_tool\", 21), \"score\", \"ts_rp\")\n",
    "as_rp = avg(subset(policy, \"pol_tool\", 21), \"score\", \"as_rp\")\n",
    "\n",
    "ts_unify = ts(subset(policy, \"pol_tool\", 23), \"score\", \"ts_unify\")\n",
    "as_unify = avg(subset(policy, \"pol_tool\", 23), \"score\", \"as_unify\")\n",
    "\n",
    "ts_edu = ts(subset(policy, \"pol_tool\", 31), \"score\", \"ts_edu\")\n",
    "as_edu = avg(subset(policy, \"pol_tool\", 31), \"score\", \"as_edu\")\n",
    "\n",
    "\n",
    "dep = pd.concat([ts_sel, as_sel, ts_int, as_int, num_ls, num_li,\n",
    "                 wts_sel, was_sel, lts_sel, las_sel, wlts_sel, wlas_sel,\n",
    "                 ts_small, ts_medium, ts_big, ts_mega, ts_big_mega, \n",
    "                 as_small, as_medium, as_big, as_mega, as_big_mega, \n",
    "                 wts_small, wts_medium, wts_big, wts_mega, wts_big_mega,\n",
    "                 was_small, was_medium, was_big, was_mega, was_big_mega], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Clustering analysis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import seaborn\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "\n",
    "\n",
    "# 3.1 Try different combinations\n",
    "\n",
    "X0 = dep\n",
    "\n",
    "X1 = dep.loc[:,[\"ts_int\", \"as_int\", \"lts_sel\", \"las_sel\", \n",
    "                \"ts_small\", \"ts_medium\", \"ts_big\", \"ts_mega\",\n",
    "                \"as_small\", \"as_medium\", \"as_big\", \"as_mega\"]]\n",
    "\n",
    "X2 = dep.loc[:,['ts_int','as_int','lts_sel','las_sel','ts_sel','as_sel',\n",
    "                \"ts_small\", \"ts_medium\", \"ts_big\", \"ts_mega\",\n",
    "                \"as_small\", \"as_medium\", \"as_big\", \"as_mega\"]]\n",
    "\n",
    "X3 = dep.loc[:,['ts_int','as_int','lts_sel','las_sel','ts_sel','as_sel',\n",
    "                \"ts_small\", \"ts_medium\", \"ts_big_mega\",\n",
    "                \"as_small\", \"as_medium\", \"as_big_mega\"]]\n",
    "\n",
    "W1 = dep.loc[:,['ts_int','as_int','wlts_sel','wlas_sel',\n",
    "                \"wts_small\", \"wts_medium\", \"wts_big\", \"wts_mega\",\n",
    "                \"was_small\", \"was_medium\", \"was_big\", \"was_mega\"]]\n",
    "\n",
    "W2 = dep.loc[:,['ts_int','as_int','wlts_sel','wlas_sel','wts_sel','was_sel',\n",
    "                \"wts_small\", \"wts_medium\", \"wts_big\", \"wts_mega\",\n",
    "                \"was_small\", \"was_medium\", \"was_big\", \"was_mega\"]]\n",
    "\n",
    "W3 = dep.loc[:,['ts_int','as_int','wlts_sel','wlas_sel','wts_sel','was_sel',\n",
    "                \"wts_small\", \"wts_medium\", \"wts_big_mega\",\n",
    "                \"was_small\", \"was_medium\", \"was_big_mega\"]]\n",
    "\n",
    "## X 和 W 最佳，X分3个，W分4个 \n",
    "\n",
    "def clustering(X,n):\n",
    "    clsmodel = AgglomerativeClustering(n_clusters=n, linkage='ward').fit(X)\n",
    "    clusters = pd.DataFrame({'cluster':clsmodel.fit_predict(X)}, index = dep.index[:])\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def plot_dendrogram(X,threshold):   \n",
    "    plt.style.use('ggplot')\n",
    "    %matplotlib notebook\n",
    "\n",
    "    proname = {11:'Beijing',12:\"Tianjin\",13:'Hebei',14:'Shanxi',15:'Inner Mongolia',21:'Liaoning',22:'Jilin',23:'Heilongjiang',\n",
    "              31:'Shanghai',32:'Jiangsu',33:'Zhejiang',34:'Anhui',35:'Fujian',36:'Jiangxi',37:'Shandong',41:'Henan',42:'Hubei',\n",
    "               43:'Hunan',44:'Guangdong',45:'Guangxi',46:'Hainan',50:'Chongqing',51:'Sichuan',52:'Guizhou',53:'Yunnan',54:'Xizang',\n",
    "              61:'Shaanxi',62:'Gansu',63:'Qinghai',65:'Xinjiang'}\n",
    "\n",
    "    from scipy.cluster.hierarchy import ward, dendrogram\n",
    "    plt.figure()\n",
    "    dendrogram(ward(X), labels=[proname[province] for province in dep.index[:]], color_threshold=threshold)\n",
    "    for item in plt.gca().xaxis.get_ticklabels():\n",
    "        item.set_rotation(90)\n",
    "    plt.subplots_adjust(bottom=0.26)\n",
    "    plt.gca().tick_params(bottom=False,left=False)\n",
    "    plt.show()\n",
    "\n",
    "plot_dendrogram(X2,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Choice of cluster number: validation statistic\n",
    "\n",
    "from sklearn.metrics import silhouette_score as sh, calinski_harabaz_score as ch, davies_bouldin_score as db\n",
    "\n",
    "def stat(X, alg_score, name = None):\n",
    "    if alg_score == ch:\n",
    "        scores = [0.01*(alg_score(X,clustering(X,i)['cluster'])) for i in range(2,30)]\n",
    "    else:\n",
    "        scores = [alg_score(X,clustering(X,i)['cluster']) for i in range(2,30)]\n",
    "    \n",
    "    #return pd.DataFrame({\"No.of clusters\":range(2,30), \"Statistics\":scores}) // For illustration purpose\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def plot_stat(X):\n",
    "\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2, sharey=True)\n",
    "    ax1.plot(range(2,30), stat(X, sh), color='#CD6155',label='Silhouette score')\n",
    "    ax1.plot(range(2,30), stat(X, db), color='#AF7AC5', label='Davies Bouldin score')\n",
    "    ax1.plot(range(2,30), stat(X, ch), color='#7FB3D5', label='Calinski haradaz score')\n",
    "\n",
    "    ax1.set_ylim([0,1.0])\n",
    "    ax1.set_xticks([2,3,4,5,10,15,20,25,30])\n",
    "\n",
    "    ax2.plot(range(2,6), stat(X, sh)[:4], color='#CD6155',label='Silhouette score')\n",
    "    ax2.plot(range(2,6), stat(X, db)[:4], color='#AF7AC5', label='Davies Bouldin score')\n",
    "    ax2.plot(range(2,6), stat(X, ch)[:4], color='#7FB3D5', label='Calinski haradaz score')\n",
    "\n",
    "    ax2.set_xticks([2,3,4,5])\n",
    "\n",
    "\n",
    "    for spine in ['top', 'right']:\n",
    "        ax1.spines[spine].set_visible(False)\n",
    "        ax2.spines[spine].set_visible(False)\n",
    "\n",
    "    fig.text(0.5,0.02,'Number of Clusters', ha='center',fontsize=10)\n",
    "    fig.subplots_adjust(bottom=0.11)\n",
    "    fig.suptitle('Different Index Scores for the Unweighted Clustering', fontsize=10)\n",
    "    #plt.legend(bbox_to_anchor=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
